## spring cloud 知识点总结

### spring cloud Feign

在应用主类上添加@EnableFeignClients注解，来开启Spring cloud Feign功能。

```java
@EnableFeignClients
@EnableDiscoveryClient
@SpringBootApplication
public class FeignconsumerApplication {

   public static void main(String[] args) {
      SpringApplication.run(FeignconsumerApplication.class, args);
   }

}

// 通过@FeignClient 注解指定服务名来绑定服务。 通过fallback 属性来实现服务降级
@FeignClient(value = "hello-service", configuration = DisableHystrixConfiguration.class,
fallback = HelloServiceFallback.class)
public interface HelloService {

    @RequestMapping(value = "/hello")
    public String hello();

    @RequestMapping(value = "/hello1")
    public String hello1(@RequestParam("name") String name);

    @RequestMapping(value = "/hello2")
    public User hello1(@RequestHeader("name") String name , @RequestHeader("age") Integer age);


    @RequestMapping(value = "/hello3",method = RequestMethod.POST)
    public String hello1(@RequestBody User user);
}

/**
 *   禁用  Hystrix 配置 在@FeigenClient 注解通过configuration引入该类，可以实现针对
 *   某一个客户端的禁用Hystrix
 */
@Configuration
public class DisableHystrixConfiguration {

    @Bean
    @Scope("prototype")
    public Feign.Builder feignBuilder(){
        return Feign.builder();
    }
}
```

### Spring cloud Zuul

在应用主类上，使用@EnableZuulProxy注解开启Zuul的API网关功能

![image-20210425123803654](总结知识点.assets/image-20210425123803654.png)

```java
@EnableZuulProxy
@SpringBootApplication
public class EurekaApplication {

   public static void main(String[] args) {
      SpringApplication.run(EurekaApplication.class, args);
   }

}

# URL pattern
# 使用路径方式匹配路由规则。
# 参数key结构： zuul.routes.customName.path=xxx
# 用于配置路径匹配规则。
# 其中customName自定义。通常使用要调用的服务名称，方便后期管理
# 可使用的通配符有： * ** ?
# ? 单个字符
# * 任意多个字符，不包含多级路径
# ** 任意多个字符，包含多级路径
zuul.routes.eureka-application-service.path=/api/**
# 参数key结构： zuul.routes.customName.url=xxx
# url用于配置符合path的请求路径路由到的服务地址。
zuul.routes.eureka-application-service.url=http://127.0.0.1:8080/
```

**Zuul的作用**

​	1、统一入口：为全部服务提供一个唯一的入口，网关起到外部与内部隔离的作用。

​	2、鉴权校验：识别每个请求的权限，拒绝不符合条件的请求。

​	3、动态路由：动态的将请求路由到不同的后端集群中。

​	4、过滤恶意请求，设置IP白名单、限流。

**Zuul网关过滤器**

​	1、pre - 前置过滤器，在请求被路由之前执行，主要做一些前置加工，如身份认证，日志记录等。

​	2、rout过滤器：会进行具体的请求转发，找到对应的服务器实例。

​	3、post过滤器：rout或者error之后执行，可以获取实例的返回信息，可以对返回信息进行加工，收集服务信		  息，统计服务性能指标等。

​	4、error过滤器：上述三个阶段发生异常时或者远程调用超时未反馈时触发，用于处理异常，最终也会经过		  post过滤器，将结果返回给客户端。

**过滤器的生命周期**

​	 当外部HTTP请求到达API网关服务的时候，首先会进入pre前置过滤器，经过一些前置加工之后，会进入第二阶段rout过滤器，即请求转发阶段。这里的具体处理内容就是将外部请求转发到具体服务实例上，当服务实例将请求结果返回后，进入第三阶段post过滤器，该阶段可以对实例返回信息进行加工。然后将结果返回给客户端。如果在上述阶段发生异常或者请求超时异常，会进入error过滤器，处理完异常之后，最终还是要通过post过滤器将结果返回给前端。

**微服务网关Zuul和Gateway的区别**

​	Zuul：使用的是阻塞式的API，不支持长连接。不支持异步，流控由hystrix支持。

​	Gateway：提供了异步支持，提供了抽象负载均衡，提供了抽象流控。默认实现了RedisRateLimiter。

### Spring cloud config

在应用主类上使用@EnableConfigServer注解，开启Spring Cloud Config服务端

```java
@SpringBootApplication
@EnableConfigServer
public class ConfigServerApplication {

   public static void main(String[] args) {
      SpringApplication.run(ConfigServerApplication.class, args);
   }
}
# 客户端创建bootstrap.properties文件，并配置如下。
# 和git里的文件名对应
spring.application.name=config
# 远程仓库的分支
spring.cloud.config.label=master
# dev 开发环境配置文件 |  test 测试环境  |  pro 正式环境
# 和git里的文件名对应
#spring.cloud.config.profile=default
# 指明配置服务中心的网址
spring.cloud.config.uri= http://localhost:8888/
server.port=8080
```

### Spring Boot 知识点

**Spring boot 的核心注解**

启动类上面的注解是@SpringBootApplication，它也是 Spring Boot 的核心注解，主要组合包含了以下 3 个注解：

@SpringBootConfiguration：组合了 @Configuration 注解，实现配置文件的功能。

@EnableAutoConfiguration：打开自动配置的功能，也可以关闭某个自动配置的选项，如关闭数据源自动配置功能： @SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })。

@ComponentScan：Spring组件扫描

**Spring boot的自动配置原理**

@SpringBootApplication是一个复合注解，包含一个@EnanbleAutoConfiguration注解，表示开启自动配置，该注解也是一个符合注解，通过@Import注解导入AutoConfigurationImportSelector的selectImports()方法扫描所有jar包中META-INF/spring.factories配置文件，该配置文件里面都是需要自动加载的配置类，都是以AuotConfiguration结尾来命名的，实际是一个JavaConfig形式的Spring配置类，在该类上会有一个@EnableConfigurationProperties注解，该注解负责导入这个已经绑定了属性的bean到spring的容器中，@ConfigurationProperties注解作用是从配置文件中绑定属性到对应的bean上。如server.port

```java
@Configuration
@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE)
@ConditionalOnClass(ServletRequest.class)
@ConditionalOnWebApplication(type = Type.SERVLET)
@EnableConfigurationProperties(ServerProperties.class)
@Import({ ServletWebServerFactoryAutoConfiguration.BeanPostProcessorsRegistrar.class,
      ServletWebServerFactoryConfiguration.EmbeddedTomcat.class,
      ServletWebServerFactoryConfiguration.EmbeddedJetty.class,
      ServletWebServerFactoryConfiguration.EmbeddedUndertow.class })
public class ServletWebServerFactoryAutoConfiguration {
    ...
}

@ConfigurationProperties(prefix = "server", ignoreUnknownFields = true)
public class ServerProperties {

	/**
	 * Server HTTP port.
	 */
	private Integer port;

	/**
	 * Network address to which the server should bind.
	 */
	private InetAddress address;        
        
```

**Spring Boot配置文件读取的顺序**

如果在不同的目录中存在多个配置文件，它的读取顺序是：
 1、config/application.properties（项目根目录中config目录下）
 2、config/application.yml
 3、application.properties（项目根目录下）
 4、application.yml
 5、resources/config/application.properties（项目resources目录中config目录下）
 6、resources/config/application.yml
 7、resources/application.properties（项目的resources目录下）
 8、resources/application.yml

**Spring Boot如何使用XML文件配置**

Spring Boot 推荐使用 Java 配置而非 XML 配置，但是 Spring Boot 中也可以使用 XML 配置，通过 @ImportResource 注解可以引入一个 XML 配置。

```java
@SpringBootApplication(exclude = { DataSourceAutoConfiguration.class })
@ImportResource({"classpath*:spring/applicationContext.xml"})
@MapperScan("com.suning.epp.ppp.dao.mapper")
@EnableCaching
public class PppApplication extends SpringBootServletInitializer {
```

**Spring boot 和核心配置文件**

bootstrap.properties：是由父ApplicationContext加载，比application优加载，该文件属性不会被覆盖，配合Spring cloud config的时候会用到。

application.properties：由ApplicationContext加载，用户spring boot项目自动化配置。

**如何禁用一个特定的配置类**

```
// 可以使用 @EnableAutoConfiguration 的 exclude 属性。
@EnableAutoConfiguration(exclude={DataSourceAutoConfiguration.class})
// 可以使用注解的 excludeName 属性并指定完全限定名称。
@EnableAutoConfiguration(excludeName={Foo.class})
```

**Spring boot启动时运行一些特定的代码**

实现接口ApplicationRunner或者CommandLineRunner接口，并且重写run方法。

**如何自己实现一个Spring boot starter？**

1、引入相应的依赖jar

```java
 <dependencies>
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-configuration-processor</artifactId>
        <optional>true</optional>
    </dependency>
     <!-- 自动装配依赖 -->
    <dependency>
        <groupId>org.springframework.boot</groupId>
        <artifactId>spring-boot-autoconfigure</artifactId>
    </dependency>
</dependencies>

```

2、编写一个配置文件类，通过@ConfigurationProperties来读取指定的属性。

```
@ConfigurationProperties("target.string")
@getter
@setter
public class AutoConfigruationProperties {

    private String target;
}
```

3、编写一个自动装配的类，使用@EnableConfigurationProperties开启自动装配

```java
@Configuration
@EnableConfigurationProperties(AutoConfigruationProperties.class)
//将AutoConfigruationProperties类导入到spring上下文容器中去

@ConditionalOnClass(GetHashCodeClass.class)
public class AutoConfigrutionClass {
    @Autowired
    private AutoConfigruationProperties autoConfigruationProperties;

    @ConditionalOnMissingBean
    @Bean
    public GetHashCodeClass getHashCodeClass(){
        return new GetHashCodeClass(autoConfigruationProperties.getTarget());
    }
}
```

4、在resource/META-INF下添加spring.factories指定自动装配的类：

```
org.springframework.boot.autoconfigure.EnableAutoConfiguration=
com.myboot.AutoConfigrutionClass
在默认配置文件application.properties中添加：
target.spring.target=hello; 代码中就可以获取到对应的配置属性
```

### Spring 知识点

**Spring中有多少种IOC容器？**

1、BeanFactory：包含bean集合的一个工厂类，它的职责包括：实例化、定位、配置应用程序中的对象及建立这些对象间的依赖。不支持很多插件、功能，如：aop。使用懒加载，不支持国际化，不支持基于依赖的注解。

2、ApplicationContext：该接口扩展了BeanFactory接口，它在BeanFactory基础上提供了一些额外的功能。使用即时加载，支持国际化，支持基于依赖的注解。

FactoryBean：是一个工厂bean，可以返回bean的实例，我们可以实现该接口对bean进行额外的操作，在容器中通过getBean（String  beanName）获取Bean对象时，获取的是bean的实例对象，想要获取BeanFactory本身的实例需要在beanName前面加上$符号。如：（“$student”）

**Spring bean中的5中scope**

1、Singleton：单例，ioc容器中只有一个实例。

2、Prototype：每次请求都会产生一个新的实例。

3、Request：每一个请求都会产生一个新的实例，该实例只在当前的HTTP请求有效。

4、Session：每一个请求都会产生一个新的实例，该实例在当前HTTP Session内有效。

5、Global-session：他仅在portlet的web应用中才有用，如果在普通的web应用中使用，则会被当成session使用。

PS：再次说明request，session和global session类型只实用于web程序，通常是和XmlWebApplicationContext共同使用。

**Spring 的自动装配**

1、no：默认配置，表示没有自动装配，需要显式的去配置bean的引用。

2、byName：根据bean的名称注入对象依赖。匹配并装配和XML文件中有着相同名称的bean。

3、byType：根据类型注入对象依赖。匹配并装配和XML文件中有着相同类型的bean。

4、构造函数：通过调用类的构造函数来注意依赖项。

**如何启动Spring的注解装配**

默认情况下，spring容器未开启注解装配，通过配置<context: annotation-config/>元素来开启。

**SpringMvc的执行流程**

1.用户发送请求至前端控制器DispatcherServlet。

 2.DispatcherServlet收到请求调用处理器映射器HandlerMapping。

 3.处理器映射器根据请求url找到具体的处理器，生成处理器执行链HandlerExecutionChain(包括处理器对象和处理器拦截器)一并返回给DispatcherServlet。

 4.DispatcherServlet根据处理器Handler获取处理器适配器HandlerAdapter执行HandlerAdapter处理一系列的操作，如：参数封装，数据格式转换，数据验证等操作

 5.执行处理器Handler(Controller，也叫页面控制器)。

 6.Handler执行完成返回ModelAndView

 7.HandlerAdapter将Handler执行结果ModelAndView返回到DispatcherServlet

 8.DispatcherServlet将ModelAndView传给ViewReslover视图解析器

 9.ViewReslover解析后返回具体View

 10.DispatcherServlet对View进行渲染视图（即将模型数据model填充至视图中）。

 11.DispatcherServlet响应用户

**Spring常用的注入方式**

```java
1、构造器注入。
public class Test1 {  
    private MessageInterface message;  
    @Autowired //构造器注入  
    private Test1(MessageInterface message) {  
        this.message = message;  
    } 
    //省略getter和setter  
  }
2、接口注入
 public class Test2 {  
    @Autowired //接口注入  
    private MessageInterface messageInterface;  
    //省略getter和setter  
}
3、set方法注入
 public class Test3 {  
    private MessageInterface message;  
 
    @Autowired //setter方法注入  
    public void setMessage(MessageInterface message) {  
        this.message = message;  
    }  
    public String getMessage() {  
        return message;  
    }  
}
@Autowired：spring的注解， 默认使用byType的方式进行装配，默认情况下要求依赖对象必须存在，如果允许依赖对象为null，需要设置required=false,如果使用byName的方式进行装配，可以配合@Qualifier("xxx")注解进行使用。
@Resource：JDK的注解，默认使用byName方式进行装配，可以通过name属性（@Resource(name="xxx")）进行制定名称，如果没有name属性，默认去字段名称进行查找装配，如果没有查到就会是用byType进行查找装配。如果指定了name属性或者type属性，就会按照byName或者byType的方式进行查找，查不到就抛异常。
```

**Spring的事务传播属性**

1、PROPAGATION_REQUIRED：支持当前事务，如果当前没有事务，就新建一个事务。这是最常见的选择，也是 Spring 默认的事务的传播。如果ServiceB.methodB() 的事务级别定义为 PROPAGATION_REQUIRED，那么执行 

ServiceA.methodA() 的时候spring已经起了事务，这时调用 ServiceB.methodB()，ServiceB.methodB() 看到自己

已经运行在 ServiceA.methodA() 的事务内部，就不再起新的事务。假如 ServiceB.methodB() 运行的时候发现自

己没有在事务中，他就会为自己分配一个事务。这样，在 ServiceA.methodA() 或者在 ServiceB.methodB() 内的任何地方出现异常，事务都会被回滚。

2、PROPAGATION_REQUIRES_NEW：新建事务，如果当前存在事务，把当前事务挂起。新建的事务将和被挂起的事务没有任何关系，是两个独立的事务，外层事务失败回滚之后，不能回滚内层事务执行的结果，内层事务失败抛出异常，外层事务捕获，也可以不处理回滚操作。

3、PROPAGATION_SUPPORTS：支持当前事务，如果当前没有事务，就以非事务方式执行。

4、PROPAGATION_MANDATORY：支持当前事务，如果当前没有事务，就抛出异常。

5、PROPAGATION_NOT_SUPPORTED：以非事务方式执行操作，如果当前存在事务，就把当前事务挂起。

6、PROPAGATION_NEVER：以非事务方式执行，如果当前存在事务，则抛出异常。

7、PROPAGATION_NESTED：如果一个活动的事务存在，则运行在一个嵌套的事务中。如果没有活动事务，则按REQUIRED属性执行。它使用了一个单独的事务，这个事务拥有多个可以回滚的保存点。内部事务的回滚不会对外部事务造成影响。它只对DataSourceTransactionManager事务管理器起效。

a、如果内部事务抛出异常，进行回滚，可以捕获异常，执行异常分支逻辑。

b、内部事务抛出异常，回滚到SavePoint，外部事务根据配置可以自己决定是提交事务还是回滚事务。

**SpringMVC中的拦截器和Servlet中的filter有什么区别？**

1、Filter：依赖于servlet容器，在请求进入容器后，未进入servlet之前进行预处理，在访问结束之后可以进行后续处理。使用Filter可以对请求修改字符编码，过滤低俗文字等。在容器初始化的时候调用一次，生命周期和servlet相同。执行顺序与web.xml的配置顺序有关。

2、interceptor：依赖于springMVC框架，基于java反射实现的，是AOP的一种，拦截器只能拦截Controller的请求，对其他的静态资源的访问不能拦截。可以在一个controller中多次使用，preHandle()，postHandle()，afterCompletion()方法。执行顺序与SpringMVC的配置文件中的配置顺序有关。

**Spring中如何解决bean的循环依赖？**

Spring的单例bean的初始化过程主要分为三步：

1、createBeanInstance：实例化，调用对象的构造方法进行实例化。

2、populateBean：填充属性，对多bean的依赖属性进行填充。

3、initializeBean：调用spring xml的init()方法，实现bean的初始化。

Spring的bean在第一步和第二步的时候容易产生循环依赖。解决问题主要是使用三级缓存。

```java
singletonObjects指单例对象的cache （一级缓存）
private final Map<String, Object> singletonObjects = new ConcurrentHashMap<String, Object>(256);

earlySingletonObjects指提前曝光的单例对象的cache（二级缓存）
private final Map<String, Object> earlySingletonObjects = new HashMap<String, Object>(16);

singletonFactories指单例对象工厂的cache（三级缓存）
private final Map<String, ObjectFactory<?>> singletonFactories = new HashMap<String, ObjectFactory<?>>(16);

protected Object getSingleton(String beanName, boolean allowEarlyReference) {
 从一级缓存获取
   Object singletonObject = this.singletonObjects.get(beanName);
   if (singletonObject == null && isSingletonCurrentlyInCreation(beanName)) {
      synchronized (this.singletonObjects) {
       从二级缓存获取
         singletonObject = this.earlySingletonObjects.get(beanName);
         if (singletonObject == null && allowEarlyReference) {
          从三级缓存获取
            ObjectFactory<?> singletonFactory = this.singletonFactories.get(beanName);
            if (singletonFactory != null) {
               singletonObject = singletonFactory.getObject();
               this.earlySingletonObjects.put(beanName, singletonObject);
               this.singletonFactories.remove(beanName);
            }
         }
      }
   }
   return (singletonObject != NULL_OBJECT ? singletonObject : null);
}
```

首先Spring会调用getSingleton(String beanName, boolean allowEarlyReference)来获取想要的单例对象，首先会在singletonObjects的一级缓存的集合中去获取对象，如果没有获取成功的话调用isSingletonCurrentlyInCreation(beanName)判断单例对象是否在创建中，如果是会从二级缓存（earlySingletionObjects）中获取，如果又没有获取到的话，根据传进来的allowEarlyReference字段判断是否能从三级缓存（objectFactory）中获取，如果可以，从三级缓存中获取对应的实例对象后，删除三级缓存中的实例对象，并添加到二级缓存中去。如A对象实例化之后，进行属性填充发现需要依赖B对象，此时去getBean（B）,由于B需要依赖A，getBean（A）；先从一级缓存获取，由于A没有初始化完成获取不到，去二级缓存中获取（也没有），去三级缓存中获取，可以获取未初始化的A的实例，B完成初始化，并将自己放入一级缓存中，然后A也能从一级缓存中获取B然后完成初始化。

通过三级缓存加上“提前曝光”机制，配合java的对象引用原理，可以解决setter方法的循环依赖。构造方法的循环依赖无法解决。

**Spring容器的bean什么时候被实例化**

（1）如果你使用BeanFactory作为Spring Bean的工厂类，则所有的bean都是在第一次使用该Bean的时候实例化
（2）如果你使用ApplicationContext作为Spring Bean的工厂类，则又分为以下几种情况：
如果bean的scope是singleton的，并且lazy-init为false（默认是false，所以可以不用设置），则 ApplicationContext启动的时候就实例化该Bean，并且将实例化的Bean放在一个map结构的缓存中，下次再使 用该 Bean的时候，直接从这个缓存中取
如果bean的scope是singleton的，并且lazy-init为true，则该Bean的实例化是在第一次使用该Bean的时候进行实例化。
如果bean的scope是prototype的，则该Bean的实例化是在第一次使用该Bean的时候进行实例化。

**Spring bean的生命周期**

**Spring bean的加载流程**



初始化环境—>加载配置文件—>实例化Bean—>调用Bean显示信息

首先从大的几个核心步骤来去说明，因为Spring中的具体加载过程和用到的类实在是太多了。

（1）、首先是先从AbstractBeanFactory中去调用doGetBean（name, requiredType, final Object[] args, boolean typeCheckOnly【这个是判断进行创建bean还是仅仅用来做类型检查】）方法，然后第一步要做的就是先去对传入的参数name进行做转换，因为有可能传进来的name=“&XXX”之类，需要去除&符号

（2）、然后接着是去调用getSingleton（）方法，其实在上一个面试题中已经提到了这个方法，这个方法就是利用“三级缓存” 来去避免循环依赖问题的出现的。【这里补充一下，只有在是单例的情况下才会去解决循环依赖问题】

（3）、对从缓存中拿到的bean其实是最原始的bean，还未长大，所以这里还需要调用getObjectForBeanInstance（Object beanInstance, String name, String beanName, RootBeanDefinition mbd）方法去进行实例化。

（4）、然后会解决单例情况下尝试去解决循环依赖，如果isPrototypeCurrentlyInCreation（beanName）返回为true的话，会继续下一步，否则throw new BeanCurrentlyInCreationException(beanName);

（5）、因为第三步中缓存中如果没有数据的话，就直接去parentBeanFactory中去获取bean，然后判断containsBeanDefinition（beanName）中去检查已加载的XML文件中是否包含有这样的bean存在，不存在的话递归去getBean（）获取，如果没有继续下一步

（6）、这一步是吧存储在XML配置文件中的GernericBeanDifinition转换为RootBeanDifinition对象。这里主要进行一个转换，如果父类的bean不为空的话，会一并合并父类的属性

（7）、这一步核心就是需要跟这个Bean有关的所有依赖的bean都要被加载进来，通过刚刚的那个RootBeanDifinition对象去拿到所有的beanName,然后通过registerDependentBean（dependsOnBean, beanName）注册bean的依赖

（8）、然后这一步就是会根据我们在定义bean的作用域的时候定义的作用域是什么，然后进行判断在进行不同的策略进行创建（比如isSingleton、isPrototype）

（9）、这个是最后一步的类型装换，会去检查根据需要的类型是否符合bean的实际类型去做一个类型转换。Spring中提供了许多的类型转换器

### Mybatis

**mybatis中#{}和${}的区别是什么？**

#{}预编译处理：在处理#{}时会替换成为？，调用PreparedStatement的set方法来赋值。可以防止sql注入，更安全。

${}字符串替换：处理${}会直接替换成变量值。

**Mybatis的分页方式？**

1、数组分页，直接将所有的数据查出来，通过List.subList(firstIndex，lastIndex);截取list实现分页。

2、sql分页

```java
<select id="queryStudentsBySql" parameterType="map" resultMap="studentmapper">
        select * from student limit #{currIndex} , #{pageSize}
</select>
```

3、拦截器分页

4、RowBounds实现分页。

**mybatis如何编写自定义插件？**

Configuration 初始化基础配置，比如MyBatis的别名等，一些重要的类型对象，如，插件，映射器，ObjectFactory和typeHandler对象，MyBatis所有的配置信息都维持在Configuration对象之中

SqlSessionFactory  SqlSession工厂

SqlSession 作为MyBatis工作的主要顶层API，表示和数据库交互的会话，完成必要数据库增删改查功能

Executor MyBatis执行器，是MyBatis 调度的核心，负责SQL语句的生成和查询缓存的维护

StatementHandler   封装了JDBC Statement操作，负责对JDBC statement 的操作，如设置参数、将Statement结果集转换成List集合。

ParameterHandler   负责对用户传递的参数转换成JDBC Statement 所需要的参数，

ResultSetHandler    负责将JDBC返回的ResultSet结果集对象转换成List类型的集合；

TypeHandler          负责java数据类型和jdbc数据类型之间的映射和转换

MappedStatement   MappedStatement维护了一条<select|update|delete|insert>节点的封装， 

SqlSource            负责根据用户传递的parameterObject，动态地生成SQL语句，将信息封装到BoundSql对象中，并返回

BoundSql 表示动态生成的SQL语句以及相应的参数信息

```java
/**
* @Description:    类功能说明：为mybatis的update操作添加拦截器，用来在更新数据时更新modifydate
* @Title:          UpdateInterceptor
	mybatis支持对Executor、StatementHandler、PameterHandler、ResultSetHandler接口进行拦截。
*/
@Intercepts({@Signature(type = Executor.class, method = "update", args = {MappedStatement.class, Object.class})})
public class UpdateInterceptor implements Interceptor{

    private Logger log = LoggerFactory.getLogger(UpdateInterceptor.class);

    @Override
    public Object intercept(Invocation invocation) throws Throwable {
        MappedStatement mappedStatement = (MappedStatement) invocation.getArgs()[0];
        //注解中method的值
        String methodName = invocation.getMethod().getName();
        //sql类型
        SqlCommandType sqlCommandType = mappedStatement.getSqlCommandType();
        if ("update".equals(methodName)) {
            Object object = invocation.getArgs()[1];
            Date currentDate = new Date(System.currentTimeMillis());
            //对有要求的字段填值
            if (SqlCommandType.UPDATE.equals(sqlCommandType)) {
                Field[] fields = object.getClass().getSuperclass().getDeclaredFields();
                for (Field field : fields){
                    if ("modify_date".equals(field.getName())){
                        Method method = object.getClass().getMethod("setModify_date",Date.class);
                        method.invoke(object,currentDate);
                        log.info("更新操作时设置modify_date:{}", currentDate);
                        break;
                    }
                }
            }
        }
        return invocation.proceed();
    }

    @Override
    public Object plugin(Object target) {
        return Plugin.wrap(target, this);
    }

    @Override
    public void setProperties(Properties properties) {
    }

}
```

**Mybatis的一级缓存和二级缓存**

1、一级缓存：是sqlSession级别的缓存，在同一个sqlSession中执行相同的SQL，第一次会查询数据库，并写入到缓存中，第二次会直接从缓存中获取。当发生增删改的操作的时候会清空一级缓存，sqlSession关闭的时候也会清空一级缓存。Mybatis默认开启一级缓存。

2、二级缓存：是基于mapper文件的namespace的，多个sqlSession可以共享同一个mapper的二级缓存，默认是不开启的。实现二级缓存需要配置<cache/> ，并且pojo必须是实现了Serializable接口。所有的select语句会被缓存，增删改语句会重新刷新缓存。

```java
<!--开启本mapper的namespace下的二级缓存-->
    <!--
        eviction:代表的是缓存回收策略，目前MyBatis提供以下策略。
        (1) LRU,最近最少使用的，一处最长时间不用的对象
        (2) FIFO,先进先出，按对象进入缓存的顺序来移除他们
        (3) SOFT,软引用，移除基于垃圾回收器状态和软引用规则的对象
        (4) WEAK,弱引用，更积极的移除基于垃圾收集器状态和弱引用规则的对象。这里采用的是LRU，
                移除最长时间不用的对形象

        flushInterval:刷新间隔时间，单位为毫秒，这里配置的是100秒刷新，如果你不配置它，那么当
        SQL被执行的时候才会去刷新缓存。

        size:引用数目，一个正整数，代表缓存最多可以存储多少个对象，不宜设置过大。设置过大会导致内存溢出。
        这里配置的是1024个对象

        readOnly:只读，意味着缓存数据只能读取而不能修改，这样设置的好处是我们可以快速读取缓存，缺点是我们没有
        办法修改缓存，他的默认值是false，不允许我们修改
    -->
```

**Mybatis的延迟加载的原理？**

启用延迟加载有两种方式：第一种是在对应的<collection>或<association>标签上指定fetchType属性值为“lazy”。第二种开启全局的延迟加载。   <setting name="lazyLoadingEnabled" value="true"/>。

Mybatis仅支持association（一对一）关联对象和collection（一对多）关联集合对象的延迟加载，Mybatis先是根据正常情况创建一个返回类型对应的对象。当我们的ResultMap是包含子查询的时候，其会在我们正常返回类型对象的基础上创建对应的代理对象。通过CGLIB或者JAVASSIST来创建代理对象。我们在访问这个对象的时候都会触发延迟加载的对象信息。通过aggressiveLazyLoading来改变他的策略。设置为false时，在第一次访问代理对象才从数据库中加载出对应的信息。

**Mybatis具有哪些执行器（Executor）？**

**SimpleExecutor：**每执行一次update或select，就开启一个Statement对象，用完立刻关闭Statement对象。

**ReuseExecutor：**执行update或select，以sql作为key查找Statement对象，存在就使用，不存在就创建，用完后，不关闭Statement对象，而是放置于Map内，供下一次使用。简言之，就是重复使用Statement对象。

**BatchExecutor：**执行update（没有select，JDBC批处理不支持select），将所有sql都添加到批处理中（addBatch()），等待统一执行（executeBatch()），它缓存了多个Statement对象，每个Statement对象都是addBatch()完毕后，等待逐一执行executeBatch()批处理。与JDBC批处理相同。

## Kafka相关知识点

**kafka的基本名词**

**Broker**：kafka的节点，多个kafka集群节点组成一个kafka集群。（可以理解成一个虚拟机）

**Topic**：消息存放的主题，逻辑概念。

**Partition**：topic上的物理分组，一个topic上有多个partition，每个partition都是一个有序队列。

**Segment**：partition物理上由多个segment组成，segment存着message信息。

**Producer**：生产message发送到topic。

**Consumer**：订阅topic消费message，consumer作为一个线程来消费。

**Consumer Group**：一个Consumer Group包含多个consumer，这个可以在配置文件中配置好。同一个partition中的message只能被一个consumer消费，如果想被不同的consumer进行消费的话，这些consumer需要来自不同的Consumer Group。假如Kafka同意同一个Consumer Group中的多个consumer消费同一个message，在多线程获取同一个消息的时候需要针对消息添加悲观锁，这样影响kafka的吞吐量，如果效率不够高的话 ，可以扩展partition并新增consumer来提高吞吐量。 

**Kafka投递语义**

1、At most once：最多一次，消费者fetch消息，然后保存offset，然后进行业务处理，在处理过程中失败后者宕机，由于offest已经保存成功，会导致后续的consumenr会从最新的offest开始消费，导致数据丢失。

2、At least once：最少一次，消费者fetch消息，然后进行消息处理，最后提交offest，在提交offest的时候发生异常，导致提交失败，那么下次消费的时候还是会fetch原来未提交的offest的消息。会导致消息重复消费。

3、Exactly once：恰好一次。

**Producer向kafka发送数据，返回的ack及含义**

1、1（默认）数据发送到kafka后，经过leader成功接收消息就返回，如果此时leader宕机，则会丢失数据（没有将数据同步到follower）。

2、0表示生产者将数据发送出去就不管了，不等待任何返回，这种情况数据传输效率最高，但是可靠性最低。

3、-1表示producer需要等待ISR中的所有follower都确认接收到数据才算发送完成。ISR中所有的Replica都向Leader发送ACK时，leader才commit。在acks=-1的时候，如果ISR少于min.insync.replicas指定的数目，那么就会返回不可用。

**Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么**

ISR：In-Sync Replicas 副本同步队列

ASR：Assigned Replicas 所有副本

ISR是有leader维护的，follower从leader同步数据有一定的延迟就会把follower从ISR中踢出去，（延迟时间replica.lag.time.max.ms参数来决定，1.0版本之前还有延迟条数replica.lag.max.messages参数来决定），并存入OSR（outof-Sync Replicas）列表，新加入的follower也会先存放在OSR中。

**Partition的分配算法**

1、将所有的Broker（假设n个）和待分配的Partition排序。

2、将第i个Partition分配到（i % n）个Broker上（这个就是leader）。

3、将第i个Partition的第j个Replica分配到（(i + j ) % n）个broker上。

**Consumer Rebalance算法**

当Topic和Partition发生变化的时候，consumer都会发生Rebalance。

1、将目标下所有的topic的所有Partition都进行排序，存为P

2、将Consumer Group下所有的Consumer排序，计算G，第i个Consumer记为Ci。

3、**N=size(P)/size(G)**，向上取整

4、解除**Ci**对原来分配的Partition的消费权（i从0开始）

5、将第**i∗N**到**（i+1）∗N−1**个Partition分配给**Ci**

**Partition leader选举**

1、controller会在ZK的/brokers/ids节点注册Watch事件，一旦有broker宕机，controller会从ZK的/brokers/topics/[topic]/partitions/[partition]/state读取该partition当前的ISR，然后将其中的一个replica选出来作为leader，如果ISR中没有幸存的replica，那就将任意一个幸存的Replica作为leader（存在数据丢失的潜在风险）。如果该Partition的所有Replica都宕机了，则将新的Leader设置为-1。

2、将新的leader，ISR和新的leader_epoch及controller_epoch写入到/brokers/topics/[topic]/partitions/[partition]/state。

3、然后发送LeaderAndISRRequest给其他受影响的broker。

**Kafka如何判断一个节点是活着的？**

1、节点必须和zookeeper连接，ZK通过心跳机制检查每个节点的连接。

2、如果节点是follower，他必须能及时的同步leader的写操作，不能掩饰太久。

**partiton中segment文件存储结构**

producer发送message到某个topic，message会被均匀的分布到partition上，kafka broker收到message往对应的partition的最后一个segment上添加该消息，当消息的条数达到配置值或者发布的时间超过阈值时，segment上的消息会被flush到磁盘，只有flush到磁盘的数据才能被消费。segment达到一定的大小后将不会再往该segment写数据，broker会创建新的segment。

segment file是由一个index file（索引文件）和data file（数据文件）组成，它们两个文件是一一对应，成对出现的。

命名规则：partition全局的第一个segment从0开始，后续每一个文件名都是一个partiton的最大offset，19位数，没有数字以0补齐。

index文件保存offest-->position（物理偏移量），data文件保存msg-offset -->position；可以通过index文件的position直接映射到对应的message的position。

**如何通过offest查找到对应的message**

1、由于segment文件是以上一个文件的最后一个offset来进行命名的。使用二分法查找能够很快的根据offset查到对应的索引文件。

2、根据索引文件的offset值，快速定位到符合范围的索引。

3、根据对应的position，到data文件中查找对应的offset的值，并且遍历比较offset与目标offset进行比较。知道找到消息。

**message的物理结构**

消息是由固定长度的头部和可变长度的字节数组组成。

8 byte ：offset 表示message的offset

4 byte：message大小

4 byte：校验码，用crc32校验message

1 byte：magic，kafk服务的协议版本号

1 byte：“attributes”表示编码类型、压缩标识

4 byte：标识key的长度

value：表示实际消息数据

**kafka性能好，体现在哪里？**

1、顺序读写 
2、零拷贝 
3、分区 
4、批量发送 
5、数据压缩 

**Kafka存储在硬盘上的消息格式是什么？**

消息由一个固定长度的头部和可变长度的字节数组组成。头部包含了一个版本号和CRC32校验码。
消息长度: 4 bytes (value: 1+4+n)
版本号: 1 byte
CRC校验码: 4 bytes
具体的消息: n bytes

**Offset的保存**

在0.10版本后，kafka把这个offset的保存，从zk总剥离，保存在一个名叫__consumeroffsets topic的topic中。写进消息的key由groupid、topic、partition组成，value是偏移量offset。topic配置的清理策略是compact。总是保留最新的key，其余删掉。一般情况下，每个key的offset都是缓存在内存中，查询的时候不用遍历partition，如果没有缓存，第一次就会遍历partition建立缓存，然后查询返回。

**如何选出Consumer Group中的coordinator?**

Consumer Group 把offset写入到__consumeroffsets topic的topic中，首先确定写入哪个partiton，该partition的leader所在的broker就是被选定的coordinator。

```swift
__consumers_offsets partition =
           Math.abs(groupId.hashCode() % groupMetadataTopicPartitionCount)   
//groupMetadataTopicPartitionCount由offsets.topic.num.partitions指定，默认是50个分区。
```

**consumer的reblance流程**

1. consumer给coordinator发送JoinGroupRequest请求。
2. 这时其他consumer发heartbeat请求过来时，coordinator会告诉他们，要reblance了。
3. 其他consumer发送JoinGroupRequest请求。
4. 所有记录在册的consumer都发了JoinGroupRequest请求之后，coordinator就会在这里consumer中随便选一个leader。然后回JoinGroupRespone，这会告诉consumer你是follower还是leader，对于leader，还会把follower的信息带给它，让它根据这些信息去分配partition

5、consumer向coordinator发送SyncGroupRequest，其中leader的SyncGroupRequest会包含分配的情况。
 6、coordinator回包，把分配的情况告诉consumer，包括leader。

当partition或者消费者的数量发生变化时，都得进行reblance。

1. 增加partition
2. 增加消费者
3. 消费者主动关闭
4. 消费者宕机了
5. coordinator自己也宕机了

**auto.offset.reset参数**

`auto.offset.reset`表示如果Kafka中没有存储对应的offset信息的话（有可能offset信息被删除），消费者从何处开始消费消息。它拥有三个可选值：

- earliest：从最早的offset开始消费
- latest：从最后的offset开始消费
- none：直接抛出exception给consumer

看一下下面两个场景：

1. Consumer消费了5条消息后宕机了，重启之后它读取到对应的partition的Committed Offset为5，因此会直接从第6条消息开始读取。此时完全依赖于Committed Offset机制，和`auto.offset.reset`配置完全无关。
2. 新建了一个新的Group，并添加了一个Consumer，它订阅了一个已经存在的Topic。此时Kafka中还没有这个Consumer相应的Offset信息，因此此时Kafka就会根据`auto.offset.reset`配置来决定这个Consumer从何处开始消费消息。

**生产者的设计**

1、生产者创建一条记录，包含topic、value，key和partition是可选的，如果key有值，将key进行hash，相同的可以去相同的partiton中，如果key没值，轮询发送到partition中。

2、为了提高吞吐量，Producer将发送消息先放入内存的buffer中，然后以一次请求的方式批量发送给broker，这样大大减少broker存储消息的IO次数，影响了一定的实时性。

3、Producer端可以通过GZIP或Snappy格式对消息集合进行压缩，Consumer端需要对消息进行解压。可以减少数据量，减轻网路的传输压力。

## Redis相关知识点

**Redis哨兵模式的主要功能**
监控：不断检查主服务器和从服务器是否正常运⾏。
通知：当被监控的某个 Redis 服务器出现问题，Sentinel 通过 API 脚本向管理员或者其他应⽤程序发出通知。
自动故障转移：当主节点不能正常⼯作时，Sentinel 会开始⼀次⾃动的故障转移操作，它会将与失效主节点是主从关系的其中一个从节点升级为新的主节点，并且将其他的从节点指向新的主节点，这样人工干预就可以免了。
配置提供者：在 Redis Sentinel 模式下，客⼾端应⽤在初始化时连接的是 Sentinel 节点集合，从中获取主节点的信
息。  

**Redis哨兵工作原理**

redis的Sentinel会对master、slave、其他sentinel创建命令连接，并且对监控的master、slave创建发布/订阅。sentinel默认每2秒钟向_sentinel_hello频道发送信息，并通过订阅该频道来接受消息，自己发送的消息不处理，处理其他sentinel的消息，并更新保存。

默认情况下，Sentinel会以每秒一次的频率向所有与它创建命令连接的实例发送PING命令。并通过返回的消息来判断实例是否在线。如果实在down-after-milliseconds毫秒内没有回复，则判定为主管下线。

Sentinel发送is-master-down-by-addr命令给其他Sentinel来判断实例是否下线，当大于一般的sentinel都同意实例下线的话，该实例就会判断成为客观下线。

Sentinel默认会每10秒一次的频率向已知的主服务器和从服务器发送INFO命令，如果主服务器被标记为客观下线之后，会从10秒一次改为1秒一次。

**Sentinel选举机制**

所有的Sentinel都有资格成为领头羊，每次进行选举之后，不论选举是否成功，所有Sentinel的配置纪元（configuration epoch）的值会自增一次。

每个发现主服务器下线的Sentinel都会要求其他Sentinel将自己设置为leader，当源Sentinel像其他目标Sentinel发送is-master-down-by-addr命令，并将runid参数设置为自己的运行时ID，表示要求将自己设置为leader。其他Sentinel收到指令后会进行回复，回复中leader_runid和leader_epoch参数分别表示leader的运行时ID和配置纪元。Sentinel的选举规则是先到先得的规则，第一个请求会处理，其他请求会丢弃。源Sentinel接受到回复后，会对比runid和epoch是否是自己的配置。如果是表示目标Sentinel将自己设定为leader。当得到过半的Sentinel支持的时候，源Sentinel就会变成leader。如果再一定时间内没有选出leader，过一段时间会再次选举，直到选举出来leader为止。

**故障转移**

1、在已下线主服务器下面的从服务器中选出来一个作为master。

2、让其他从服务器都去重新复制新的主服务器。

3、将已下线的主服务器设置为新master的从服务器。

**选择从服务器的策略**

删除列表中已经下线或者断线的从服务，删除最近5秒没回复过INFO命令的从服务器， 删除与master断开超过down-after-millisenconds * 10毫秒的从服务器，此举是保证从服务的数据都是最新的数据。

从优先级、offset、runid维度来选master，首先选优先级高的，如果优先级相等，再选offset高的，如果offset相等就选runid小的。

## 面试重点

**java创建对象的几种方法**

1、通过关键字new一个对象。

2、通过反射创建一个对象。

3、通过clone创建对象。

4、通过序列化创建对象。

**对象的hashcode相同如何处理？**

拉链法:每个哈希表节点都有一个next指针,多个哈希表节点可以用next指针构成一个单向链表，被
分配到同一个索引上的多个节点可以用这个单向链表进行存储.
开放定址法:一旦发生了冲突,就去寻找下一个空的散列地址,只要散列表足够大,空的散列地址总能找
到,并将记录存入
再哈希:又叫双哈希法,有多个不同的Hash函数.当发生冲突时,使用第二个,第三个….等哈希函数计算
地址,直到无冲突.
**深拷贝和浅拷贝的区别是什么?**
浅拷贝:被复制对象的所有变量都含有与原来的对象相同的值,而所有的对其他对象的引用仍然指向
原来的对象.换言之,浅拷贝仅仅复制所考虑的对象,而不复制它所引用的对象.
深拷贝:被复制对象的所有变量都含有与原来的对象相同的值.而那些引用其他对象的变量将指向被
复制过的新对象.而不再是原有的那些被引用的对象.换言之.深拷贝把要复制的对象所引用的对象都
复制了一遍.
**final的用法**

final修饰类，类不能被继承

final修饰方法，方法不能被重写

final修饰变量，变量不能被改变。

在构造函数内对一个final域的写入,与随后把这个被构造对象的引用赋值给一个引用变量,这两个操作之
间不能重排序
初次读一个包含final域的对象的引用,与随后初次读这个final域,这两个操作之间不能重排序.

a=a+b与a+=b有什么区别吗?
+= 操作符会进行隐式自动类型转换,此处a+=b隐式的将加操作的结果类型强制转换为持有结果的类型,
而a=a+b则不会自动进行类型转换.

short s1 = 1;s1 = s1 +1;会报错，和int类型进行加运算，会变成int类型。s1 += 1;不会报错。+=表达式会对右边的结果进行强转，匹配左边的类型。

**java反射机制**

1）Class.forName(“类的路径”)；
2）类名.class
3）对象名.getClass()
4）基本类型的包装类，可以调用包装类的Type属性来获得该包装类的Class对象  

**java的类加载过程**

加载通过类的完全限定名,查找此类字节码文件,利用字节码文件创建Class对象.
验证确保Class文件符合当前虚拟机的要求,不会危害到虚拟机自身安全.
准备进行内存分配,为static修饰的类变量分配内存,并设置初始值(0或null).不包含final修饰的静态变量,
因为final变量在编译时分配.
解析将常量池中的符号引用替换为直接引用的过程.直接引用为直接指向目标的指针或者相对偏移量等.
初始化主要完成静态块执行以及静态变量的赋值.先初始化父类,再初始化当前类.只有对类主动使用时才
会初始化.
触发条件包括,创建类的实例时,访问类的静态方法或静态变量的时候,使用Class.forName反射类的时候,
或者某个子类初始化的时候.
Java自带的加载器加载的类,在虚拟机的生命周期中是不会被卸载的,只有用户自定义的加载器加载的类
才可以被卸.
**java的对象结构**

Java对象由三个部分组成：对象头、实例数据、对齐填充。
对象头由两部分组成，第一部分存储对象自身的运行时数据：哈希码、GC分代年龄、锁标识状态、线
程持有的锁、偏向线程ID（一般占32/64 bit）。第二部分是指针类型，指向对象的类元数据类型（即对
象代表哪个类）。如果是数组对象，则对象头中还有一部分用来记录数组长度。
实例数据用来存储对象真正的有效信息（包括父类继承下来的和自己定义的）
对齐填充：JVM要求对象起始地址必须是8字节的整数倍（8字节对齐）

**如何停止一个正在运行的线程？**

1、正常停止，执行完run方法，自动停止。

2、使用interrupt()方法中断线程，阻塞线程调用该方法会抛出InterruptedException，导致线程中断

**TCP的三次握手**

第一次握手：建立连接时，客户端发送syn包（syn=x）到服务器，并进入SYN_SENT状态，等待服务器确认；SYN：同步序列编号（Synchronize Sequence Numbers）。

第二次握手：服务器收到syn包，必须确认客户的SYN（ack=x+1），同时自己也发送一个SYN包（syn=y），即SYN+ACK包，此时服务器进入SYN_RECV状态；

第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK(ack=y+1），此包发送完毕，客户端和服务器进入ESTABLISHED（TCP连接成功）状态，完成三次握手。
**TCP的四次挥手**

1）客户端进程发出连接释放报文，并且停止发送数据。释放数据报文首部，FIN=1，其序列号为seq=u（等于前面已经传送过来的数据的最后一个字节的序号加1），此时，客户端进入FIN-WAIT-1（终止等待1）状态。 TCP规定，FIN报文段即使不携带数据，也要消耗一个序号。
2）服务器收到连接释放报文，发出确认报文，ACK=1，ack=u+1，并且带上自己的序列号seq=v，此时，服务端就进入了CLOSE-WAIT（关闭等待）状态。TCP服务器通知高层的应用进程，客户端向服务器的方向就释放了，这时候处于半关闭状态，即客户端已经没有数据要发送了，但是服务器若发送数据，客户端依然要接受。这个状态还要持续一段时间，也就是整个CLOSE-WAIT状态持续的时间。
3）客户端收到服务器的确认请求后，此时，客户端就进入FIN-WAIT-2（终止等待2）状态，等待服务器发送连接释放报文（在这之前还需要接受服务器发送的最后的数据）。
4）服务器将最后的数据发送完毕后，就向客户端发送连接释放报文，FIN=1，ack=u+1，由于在半关闭状态，服务器很可能又发送了一些数据，假定此时的序列号为seq=w，此时，服务器就进入了LAST-ACK（最后确认）状态，等待客户端的确认。
5）客户端收到服务器的连接释放报文后，必须发出确认，ACK=1，ack=w+1，而自己的序列号是seq=u+1，此时，客户端就进入了TIME-WAIT（时间等待）状态。注意此时TCP连接还没有释放，必须经过2∗∗MSL（最长报文段寿命）的时间后，当客户端撤销相应的TCB后，才进入CLOSED状态。
6）服务器只要收到了客户端发出的确认，立即进入CLOSED状态。同样，撤销TCB后，就结束了这次的TCP连接。可以看到，服务器结束TCP连接的时间要比客户端早一些。
**【问题1】为什么连接的时候是三次握手，关闭的时候却是四次握手？**

答：因为当Server端收到Client端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当Server端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉Client端，"你发的FIN报文我收到了"。只有等到我Server端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四步握手。

**【问题2】为什么TIME_WAIT状态需要经过2MSL(最大报文段生存时间)才能返回到CLOSE状态？**

答：虽然按道理，四个报文都发送完毕，我们可以直接进入CLOSE状态了，但是我们必须假象网络是不可靠的，有可以最后一个ACK丢失。所以TIME_WAIT状态就是用来重发可能丢失的ACK报文。在Client发送出最后的ACK回复，但该ACK可能丢失。Server如果没有收到ACK，将不断重复发送FIN片段。所以Client不能立即关闭，它必须确认Server接收到了该ACK。Client会在发送出ACK之后进入到TIME_WAIT状态。Client会设置一个计时器，等待2MSL的时间。如果在该时间内再次收到FIN，那么Client会重发ACK并再次等待2MSL。所谓的2MSL是两倍的MSL(Maximum Segment Lifetime)。MSL指一个片段在网络中最大的存活时间，2MSL就是一个发送和一个回复所需的最大时间。如果直到2MSL，Client都没有再次收到FIN，那么Client推断ACK已经被成功接收，则结束TCP连接。

**【问题3】为什么不能用两次握手进行连接？**

答：3次握手完成两个重要的功能，既要双方做好发送数据的准备工作(双方都知道彼此已准备好)，也要允许双方就初始序列号进行协商，这个序列号在握手过程中被发送和确认。

       现在把三次握手改成仅需要两次握手，死锁是可能发生的。作为例子，考虑计算机S和C之间的通信，假定C给S发送一个连接请求分组，S收到了这个分组，并发 送了确认应答分组。按照两次握手的协定，S认为连接已经成功地建立了，可以开始发送数据分组。可是，C在S的应答分组在传输中被丢失的情况下，将不知道S 是否已准备好，不知道S建立什么样的序列号，C甚至怀疑S是否收到自己的连接请求分组。在这种情况下，C认为连接还未建立成功，将忽略S发来的任何数据分 组，只等待连接确认应答分组。而S在发出的分组超时后，重复发送同样的分组。这样就形成了死锁。

**【问题4】如果已经建立了连接，但是客户端突然出现故障了怎么办？**

TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。
